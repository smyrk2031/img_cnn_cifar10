{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my-1st-try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list\n",
    "print(\"はじめ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision-Trans-Former with keras(no Finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, KFold\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.preprocessing.image import load_img, img_to_array, save_img, ImageDataGenerator\n",
    "from keras.initializers import TruncatedNormal, Constant\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop, SGD, Adam, Nadam, Adamax, Adadelta\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, LearningRateScheduler, ReduceLROnPlateau, LambdaCallback, CSVLogger\n",
    "from keras import models, layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from efficientnet.keras import EfficientNetB4,EfficientNetB3,EfficientNetB2,EfficientNetB1,EfficientNetB0,EfficientNetB5,EfficientNetB6,EfficientNetB7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "gpu_id = 0\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# 使うGPUの設定\n",
    "tf.config.set_visible_devices(physical_devices[gpu_id], 'GPU')\n",
    "\n",
    "# 動的メモリアロケート設定\n",
    "tf.config.experimental.set_memory_growth(physical_devices[gpu_id], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "data_seed = 94\n",
    "KFold_seed = 94\n",
    "EPOCHS = 10\n",
    "PATCH_SIZE = 4\n",
    "BATCH_SIZE = 64 #100\n",
    "IMAGE_SIZE = 512 #314 #512 #64 #225\n",
    "CH_NUM = 3\n",
    "\n",
    "#学習中のtrain-data分割割合\n",
    "training_percentage = 0.9\n",
    "\n",
    "# 最適化関数\n",
    "#opt = Adam(lr=0.01)\n",
    "#opt = Adadelta(lr=1.0)\n",
    "#opt = Adamax(lr=0.002)\n",
    "#opt = Nadam(lr=0.002)\n",
    "opt = \"adam\"                             #最適化関数は何使う？\"SDG\",\"adam\",\"RMSprop\", \"nadam\", \"adadelta\"\n",
    "\n",
    "# 損失係数\n",
    "LOSS = \"categorical_crossentropy\"        #損失はどうする？\"categorical_crossentropy\",\"sparse_categorical_crossentropy\",\"\"\n",
    "METRICS = [\"accuracy\"]                   #最適化する計量は？\"accuracy\",\"\",\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を取得する関数(RGBで処理したい)\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    # リサイズする\n",
    "    im_rgb = cv2.resize(im_rgb , (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    return im_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU使えているよね？？\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle用\n",
    "# 画像のful-pathリスト作成\n",
    "test_imgs = glob(\"../input/cassava-leaf-disease-classification/test_images/**.jpg\")\n",
    "# 画像のful-pathリスト作成\n",
    "imgs = glob(\"../input/cassava-leaf-disease-classification/train_images/**.jpg\")\n",
    "# 画像の名称リスト\n",
    "train_img_list = os.listdir(os.path.join(\"../input/cassava-leaf-disease-classification/train_images\"))\n",
    "# 画像のラベル名リスト\n",
    "train_label = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "# 学習データ作成準備\n",
    "samples_df = shuffle(train_label, random_state=94)\n",
    "samples_df[\"label\"] = samples_df[\"label\"].astype(\"str\")\n",
    "samples_df.head()\n",
    "\n",
    "# 画像のラベル詳細について\n",
    "#desease_list = pd.read_json(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPGPUの使用率を確認するやつ\n",
    "import subprocess\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "DEFAULT_ATTRIBUTES = (\n",
    "    'index',\n",
    "    'uuid',\n",
    "    'name',\n",
    "    'timestamp',\n",
    "    'memory.total',\n",
    "    'memory.free',\n",
    "    'memory.used',\n",
    "    'utilization.gpu',\n",
    "    'utilization.memory'\n",
    ")\n",
    "\n",
    "def get_gpu_info(nvidia_smi_path='nvidia-smi', keys=DEFAULT_ATTRIBUTES, no_units=True):\n",
    "    nu_opt = '' if not no_units else ',nounits'\n",
    "    cmd = '%s --query-gpu=%s --format=csv,noheader%s' % (nvidia_smi_path, ','.join(keys), nu_opt)\n",
    "    output = subprocess.check_output(cmd, shell=True)\n",
    "    lines = output.decode().split('\\n')\n",
    "    lines = [ line.strip() for line in lines if line.strip() != '' ]\n",
    "\n",
    "    return [ { k: v for k, v in zip(keys, line.split(', ')) } for line in lines ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(get_gpu_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local用\n",
    "# 画像のful-pathリスト作成\n",
    "test_imgs = glob(\"/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/test_images/**.jpg\")\n",
    "# 画像のful-pathリスト作成\n",
    "imgs = glob(\"/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/train_images/**.jpg\")\n",
    "# 画像の名称リスト\n",
    "train_img_list = os.listdir(os.path.join(\"/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/train_images\"))\n",
    "# 画像のラベル名リスト\n",
    "train_label = pd.read_csv(\"/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/train.csv\")\n",
    "# 学習データ作成準備\n",
    "samples_df = shuffle(train_label, random_state=94)\n",
    "samples_df[\"label\"] = samples_df[\"label\"].astype(\"str\")\n",
    "samples_df.head()\n",
    "\n",
    "# 画像のラベル詳細について\n",
    "#desease_list = pd.read_json(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\")\n",
    "\n",
    "\n",
    "samples_train = samples_df\n",
    "samples_val =samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データと評価データに分ける準備\n",
    "training_item_count = int(len(samples_df)*training_percentage)\n",
    "validation_item_count = len(samples_df)-int(len(samples_df)*training_percentage)\n",
    "training_df = samples_df[:training_item_count]\n",
    "validation_df = samples_df[training_item_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_df[\"label\"].value_counts())\n",
    "print(validation_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ランダムでサンプルデータから、学習セットを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用の準備\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "target_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "dropout_rate = 0.4\n",
    "classes_to_predict = sorted(training_df.label.unique())\n",
    "CLASS = len(classes_to_predict)\n",
    "print(\"クラス数は：\", CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_dfのランダム生成関数\n",
    "# fut_generatorで交差検証するのに使う\n",
    "\n",
    "def train_data_gen(training_item_count, data_seed):\n",
    "    global samples_train\n",
    "    samples_train = shuffle(samples_train, random_state = data_seed)\n",
    "    samples_train[\"label\"] = samples_train[\"label\"].astype(\"str\")\n",
    "    samples_train = samples_train[:training_item_count]\n",
    "    \n",
    "    return samples_train\n",
    "\n",
    "# validation_dfのランダム生成関数\n",
    "def val_data_gen(training_item_count, data_seed):\n",
    "    global samples_val\n",
    "    samples_val = shuffle(samples_val, random_state = data_seed)\n",
    "    samples_valid = samples_val\n",
    "    samples_valid[\"label\"] = samples_valid[\"label\"].astype(\"str\")\n",
    "    samples_valid = samples_valid[training_item_count:]\n",
    "    \n",
    "    return samples_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータを確認してみる\n",
    "plt.imshow(get_img(test_imgs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_img = cv2.imread(test_imgs[0])\n",
    "tes_img = cv2.resize(tes_img , (IMAGE_SIZE, IMAGE_SIZE))\n",
    "tes_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tes_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "submission = pd.read_csv(\"/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/sample_submission.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習画像を準備する部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=training_df,\n",
    "    directory=\".\\train_imgs\",\n",
    "    x_col=\"image_id\",\n",
    "    y_col=\"label\",\n",
    "    class_mode=\"sparse\",\n",
    "    target_size=(32,32),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考のやつ\n",
    "ImageDataGenerator(validation_split = 0.2,\n",
    "                                     preprocessing_function = None,\n",
    "                                     zoom_range = 0.15,\n",
    "                                     cval = 0.,\n",
    "                                     horizontal_flip = True,\n",
    "                                     vertical_flip = True,\n",
    "                                     fill_mode = 'nearest',\n",
    "                                     shear_range = 0.15,\n",
    "                                     height_shift_range = 0.15,\n",
    "                                     width_shift_range = 0.15) \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    height_shift_range = 0.15,\n",
    "    width_shift_range = 0.15\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = training_df,\n",
    "    #dataframe = train_data_gen(training_item_count, data_seed),\n",
    "    x_col='image_id',\n",
    "    y_col='label',\n",
    "    directory='/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/train_images/',\n",
    "    target_size=target_size,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    seed = 94)\n",
    "\n",
    "\n",
    "# Validation_datagenでもAugumentationをすれば、TTA的に若干の精度向上が見込まれる\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = validation_df,\n",
    "    #dataframe = val_data_gen(training_item_count, data_seed),\n",
    "    x_col='image_id',\n",
    "    y_col='label',\n",
    "    directory='/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/train_images/',\n",
    "    target_size=target_size,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed = 94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(tes_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, Add, Activation, Input\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自作モデル_02_Vit\n",
    "def MultiHead_SelfAttention(inputs, embed_dim, num_heads):\n",
    "    projection_dim = embed_dim // num_heads\n",
    "    batch_size = K.int_shape(inputs)[0]\n",
    "\n",
    "    query = Dense(embed_dim)(inputs)\n",
    "    key   = Dense(embed_dim)(inputs)\n",
    "    value = Dense(embed_dim)(inputs)\n",
    "\n",
    "    query = K.reshape(query, (batch_size, -1, num_heads, projection_dim))\n",
    "    key   = K.reshape(key,   (batch_size, -1, num_heads, projection_dim))\n",
    "    value = K.reshape(value, (batch_size, -1, num_heads, projection_dim))\n",
    "\n",
    "    query = K.permute_dimensions(query, (0, 2, 1, 3))\n",
    "    key   = K.permute_dimensions(key,   (0, 2, 1, 3))\n",
    "    value = K.permute_dimensions(value, (0, 2, 1, 3))\n",
    "\n",
    "    score = tf.matmul(query, key, transpose_b=True)\n",
    "    score = score/K.sqrt(K.cast(projection_dim, 'float32'))\n",
    "    weights = Activation('softmax')(score)\n",
    "\n",
    "    attention = tf.matmul(weights, value)\n",
    "    attention = K.permute_dimensions(attention, (0, 2, 1, 3))\n",
    "    attention = K.reshape(attention, (batch_size, -1, embed_dim))\n",
    "    output = Dense(embed_dim)(attention)\n",
    "    return output\n",
    "\n",
    "def TransformerBlock(inputs, embed_dim, num_heads, ff_dim):\n",
    "    attn_output = MultiHead_SelfAttention(inputs, embed_dim, num_heads)\n",
    "    attn_output = Dropout(0.1)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(Add()([inputs, attn_output]))\n",
    "    ffn_output = Dense(ff_dim, activation=\"relu\")(out1)\n",
    "    ffn_output = Dense(embed_dim)(ffn_output)\n",
    "    ffn_output = Dropout(0.1)(ffn_output)\n",
    "    return LayerNormalization(epsilon=1e-6)(Add()([out1, ffn_output]))\n",
    "\n",
    "class Add_Embedding_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches=64, d_model=64, batch_size=16):\n",
    "        super(Add_Embedding_Layer, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_emb = self.add_weight(shape=[1, 1, d_model], dtype=tf.float32)\n",
    "        self.pos_emb = self.add_weight(shape=[1, num_patches+1, d_model], dtype=tf.float32)\n",
    "\n",
    "    def call(self, input):\n",
    "        patch_emb = K.repeat_elements(self.patch_emb, self.batch_size, axis=0)\n",
    "        pos_emb = K.repeat_elements(self.pos_emb, self.batch_size, axis=0)\n",
    "        return K.concatenate([input, patch_emb], axis=1) + pos_emb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def make_ViT(img_size = IMAGE_SIZE, ch_size = CH_NUM, patch_size = PATCH_SIZE,\n",
    "             batch_size = BATCH_SIZE, num_layers = 4, d_model = IMAGE_SIZE,\n",
    "             num_heads = 4, mlp_dim = 128, num_classes = CLASS):\n",
    "\n",
    "    num_patches = (img_size // patch_size) ** 2\n",
    "    patch_dim = ch_size * patch_size ** 2\n",
    "\n",
    "    #inputs = Input(shape=(32, 32, 3))\n",
    "    inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CH_NUM))\n",
    "    \n",
    "    x = Rescaling(1./255)(inputs)\n",
    "    x = tf.nn.space_to_depth(x, patch_size)\n",
    "    x = K.reshape(x, (-1, num_patches, patch_dim))\n",
    "    x = Dense(d_model)(x)\n",
    "\n",
    "    x = Add_Embedding_Layer(num_patches, d_model, batch_size)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = TransformerBlock(x, d_model, num_heads, mlp_dim)\n",
    "\n",
    "    x = Dense(mlp_dim, activation=tfa.activations.gelu)(x[:, 0])\n",
    "    x = Dropout(0.1)(x)\n",
    "    y = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs=inputs, outputs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = make_ViT()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自作のモデル_01\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, CH_NUM)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "# The second convolution\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "# The third convolution\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "# The fourth convolution\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "# Flatten the results to feed into a dense layer\n",
    "model.add(layers.Flatten())\n",
    "# 128 neuron in the fully-connected layer\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(CLASS, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = Input(shape=X_train[0].shape)\n",
    "input = Input(shape=tes_img.shape)\n",
    "\n",
    "\n",
    "#model_base = VGG16(include_top=False, weights=\"imagenet\", input_tensor=input, classes=CLASS)\n",
    "#model_base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=input, input_shape=None, pooling=None, classes=CLASS)\n",
    "#model_base = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input, input_shape=None, pooling=None, alpha=1.0, depth_multiplier=1, classes=CLASS)\n",
    "#model_base = VGG19(include_top=False, weights='imagenet', input_tensor=input, input_shape=None, pooling=None, classes=CLASS)\n",
    "\n",
    "# ここEfficientNet(weights='noisy-student'\"imagenet\"も試す)\n",
    "model_base = EfficientNetB0(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
    "\n",
    "#model = VGG16(include_top=False, weights=\"imagenet\", input_shape=input)\n",
    "#model_name = \"VGG16-fine\"\n",
    "model_name = \"efnB4-fine\"\n",
    "#model_name = \"Resnet50-fine\"\n",
    "\n",
    "print(\"model取得完了\")\n",
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畳み込みベースのvgg16を凍結せずに再学習層を残す\n",
    "print(\"凍結するけど、再学習層を残す！\")\n",
    "model_base.trainable = True\n",
    "\n",
    "# このフラグがFalseの層は凍結される\n",
    "set_flg = False\n",
    "\n",
    "# どの層まで凍結するか・・・。。\n",
    "#VGG16は、block5_conv1\n",
    "#resnet50は、res5c_branch2c ,res5c_branch2a\n",
    "#efficientNetB4は、top_convか、block7b_project_conv、block7b_se_reduceあたり？？\n",
    "# block6a_expand_convが、6の層をa以降を解凍する⇒メモリエラーで無理\n",
    "# block7a_expand_conv、⇒メモリエラーで無理\n",
    "\n",
    "for layer in model_base.layers:\n",
    "    if layer.name == \"top_conv\":  #\"block5_conv1\"というレイヤー以下はすべて trainable を True とする。\n",
    "        set_flg = True\n",
    "    if set_flg == True:\n",
    "        layer.trainable = True\n",
    "        print(\"set trainable True 凍結しない！\")\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        print(\"set trainable False 凍結！\")\n",
    "\n",
    "# モデルの確認\n",
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全結合層の追加\n",
    "print(\"全結合層の追加\")\n",
    "model = models.Sequential()\n",
    "model.add(model_base)\n",
    "#model.add(layers.Flatten(input_shape=(1,1,500)))\n",
    "#model.add(layers.Dense(500, activation='relu'))\n",
    "#model.add(layers.Flatten(input_shape=(1,1,CLASS)))\n",
    "#model.add(layers.Dense(CLASS, activation='relu'))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "#model.add(layers.Dense(CLASS, activation='softmax'))\n",
    "\n",
    "# 全結合層の各初期化、正則化の設定はきちんとする必要がある\n",
    "model.add(layers.Dense(CLASS, activation='softmax', kernel_initializer='uniform', kernel_regularizer=K.regularizers.l2(0.)))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# kerasの全結合層で利用可能な正規化\n",
    "K.regularizers.l1(0.)\n",
    "K.regularizers.l2(0.)\n",
    "K.regularizers.l1_l2(l1=0.01, l2=0.01)\n",
    "\"\"\"\n",
    "\n",
    "print(\"FineTuneing!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# めも\n",
    "conv_base = VGG16(weights = 'imagenet' , include_top = False , input_tensor=input, classes=CLASS)\n",
    "conv_base.trainable = False # Freeze VGG16 base\n",
    "model_2 = Sequential()\n",
    "model_2.add(conv_base)\n",
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dense(512 , activation = \"relu\"))\n",
    "model_2.add(layers.Dense(units = 5 , activation = \"softmax\"))\n",
    "model_2.summary()\n",
    "model_2.compile(loss = LOSS, optimizer = opt, metrics = METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = LOSS, optimizer = opt, metrics = METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"accuracy\", min_delta=0.000, patience=20, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_VALID,STEP_SIZE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU使えているよね？？\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "# メモリ制限するらしい\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# チェックポイントで定期的にモデルを保存する\n",
    "# ファイル名に(`str.format`を使って)エポック数を埋め込む\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#checkpoint_path = \"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_path = \"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/cp-{epoch:04d}.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = ModelCheckpoint(filepath = checkpoint_path, \n",
    "                                monitor='val_loss', \n",
    "                                verbose=0, \n",
    "                                save_best_only=False, \n",
    "                                save_weights_only=False, \n",
    "                                mode='min', \n",
    "                                period=1)\n",
    "hist = History()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T = time.time()\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID,\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1,\n",
    "                              callbacks=[es, cp_callback, hist],\n",
    "                              shuffle=True,\n",
    "                              workers=20\n",
    "                             )\n",
    "\n",
    "print(\"学習の処理時間：\", str(time.time() - T), \" [sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここから"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold(fit_generatorで似た感じに作って)、アンサンブルする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル作成_複数作るよ！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold用\n",
    "input = Input(shape=tes_img.shape)\n",
    "T_model_in = time.time()\n",
    "#model_base = VGG16(include_top=False, weights=\"imagenet\", input_tensor=input, classes=CLASS)\n",
    "#model_base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=input, input_shape=None, pooling=None, classes=CLASS)\n",
    "#model_base = MobileNetV2(include_top=False, weights='imagenet', input_tensor=input, input_shape=None, pooling=None, alpha=1.0, depth_multiplier=1, classes=CLASS)\n",
    "#model_base = VGG19(include_top=False, weights='imagenet', input_tensor=input, input_shape=None, pooling=None, classes=CLASS)\n",
    "#model_base = VGG16(include_top=False, weights=\"imagenet\", input_shape=input)\n",
    "\n",
    "use_model = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=input, input_shape=None, pooling=None, classes=CLASS)\n",
    "#use_model = EfficientNetB2(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
    "\n",
    "\n",
    "# ここEfficientNet(weights='noisy-student'\"imagenet\"も試す)\n",
    "#model_base_1 = EfficientNetB0(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
    "model_base_1 = use_model\n",
    "model_base_1.trainable = True\n",
    "set_flg = False\n",
    "for layer in model_base_1.layers:\n",
    "    if layer.name == \"top_conv\":  #\"block5_conv1\"というレイヤー以下はすべて trainable を True とする。\n",
    "        set_flg = True\n",
    "    if set_flg == True:\n",
    "        layer.trainable = True\n",
    "        print(\"set trainable True 凍結しない！\")\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        #print(\"set trainable False 凍結！\")\n",
    "print(\"全結合層の追加\")\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(model_base_1)\n",
    "model_1.add(layers.GlobalAveragePooling2D())\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "model_1.add(layers.Dense(CLASS, activation='softmax', kernel_initializer='uniform', kernel_regularizer=K.regularizers.l2(0.)))\n",
    "model_1.compile(loss = LOSS, optimizer = opt, metrics = METRICS)\n",
    "print(\"FineTuneing!!\")\n",
    "print(\"モデルの取得時間：\", str(time.time() - T_model_in), \"[sec]\")\n",
    "\n",
    "\n",
    "#model_base_2 = EfficientNetB0(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
    "model_base_2 = use_model\n",
    "model_base_2.trainable = True\n",
    "set_flg = False\n",
    "for layer in model_base_2.layers:\n",
    "    if layer.name == \"top_conv\":  #\"block5_conv1\"というレイヤー以下はすべて trainable を True とする。\n",
    "        set_flg = True\n",
    "    if set_flg == True:\n",
    "        layer.trainable = True\n",
    "        print(\"set trainable True 凍結しない！\")\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        #print(\"set trainable False 凍結！\")\n",
    "print(\"全結合層の追加\")\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(model_base_2)\n",
    "model_2.add(layers.GlobalAveragePooling2D())\n",
    "model_2.add(layers.Dropout(0.5))\n",
    "model_2.add(layers.Dense(CLASS, activation='softmax', kernel_initializer='uniform', kernel_regularizer=K.regularizers.l2(0.)))\n",
    "model_2.compile(loss = LOSS, optimizer = opt, metrics = METRICS)\n",
    "print(\"FineTuneing!!\")\n",
    "print(\"モデルの取得時間：\", str(time.time() - T_model_in), \"[sec]\")\n",
    "\n",
    "\n",
    "#model_base_3 = EfficientNetB0(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
    "model_base_3 = use_model\n",
    "model_base_3.trainable = True\n",
    "set_flg = False\n",
    "for layer in model_base_3.layers:\n",
    "    if layer.name == \"top_conv\":  #\"block5_conv1\"というレイヤー以下はすべて trainable を True とする。\n",
    "        set_flg = True\n",
    "    if set_flg == True:\n",
    "        layer.trainable = True\n",
    "        print(\"set trainable True 凍結しない！\")\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        #print(\"set trainable False 凍結！\")\n",
    "print(\"全結合層の追加\")\n",
    "model_3 = models.Sequential()\n",
    "model_3.add(model_base_3)\n",
    "model_3.add(layers.GlobalAveragePooling2D())\n",
    "model_3.add(layers.Dropout(0.5))\n",
    "model_3.add(layers.Dense(CLASS, activation='softmax', kernel_initializer='uniform', kernel_regularizer=K.regularizers.l2(0.)))\n",
    "model_3.compile(loss = LOSS, optimizer = opt, metrics = METRICS)\n",
    "print(\"FineTuneing!!\")\n",
    "print(\"モデルの取得時間：\", str(time.time() - T_model_in), \"[sec]\")\n",
    "\n",
    "\n",
    "#model_base_4 = EfficientNetB0(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
    "model_base_4 = use_model\n",
    "model_base_4.trainable = True\n",
    "set_flg = False\n",
    "for layer in model_base_4.layers:\n",
    "    if layer.name == \"top_conv\":  #\"block5_conv1\"というレイヤー以下はすべて trainable を True とする。\n",
    "        set_flg = True\n",
    "    if set_flg == True:\n",
    "        layer.trainable = True\n",
    "        print(\"set trainable True 凍結しない！\")\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        #print(\"set trainable False 凍結！\")\n",
    "print(\"全結合層の追加\")\n",
    "model_4 = models.Sequential()\n",
    "model_4.add(model_base_4)\n",
    "model_4.add(layers.GlobalAveragePooling2D())\n",
    "model_4.add(layers.Dropout(0.5))\n",
    "model_4.add(layers.Dense(CLASS, activation='softmax', kernel_initializer='uniform', kernel_regularizer=K.regularizers.l2(0.)))\n",
    "model_4.compile(loss = LOSS, optimizer = opt, metrics = METRICS)\n",
    "print(\"FineTuneing!!\")\n",
    "print(\"モデルの取得時間：\", str(time.time() - T_model_in), \"[sec]\")\n",
    "\n",
    "\n",
    "#model_base_5 = EfficientNetB0(input_shape=input_shape, weights=\"imagenet\", include_top=False)\n",
    "model_base_5 = use_model\n",
    "model_base_5.trainable = True\n",
    "set_flg = False\n",
    "for layer in model_base_5.layers:\n",
    "    if layer.name == \"top_conv\":  #\"block5_conv1\"というレイヤー以下はすべて trainable を True とする。\n",
    "        set_flg = True\n",
    "    if set_flg == True:\n",
    "        layer.trainable = True\n",
    "        print(\"set trainable True 凍結しない！\")\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        #print(\"set trainable False 凍結！\")  \n",
    "print(\"全結合層の追加\")\n",
    "model_5 = models.Sequential()\n",
    "model_5.add(model_base_5)\n",
    "model_5.add(layers.GlobalAveragePooling2D())\n",
    "model_5.add(layers.Dropout(0.5))\n",
    "model_5.add(layers.Dense(CLASS, activation='softmax', kernel_initializer='uniform', kernel_regularizer=K.regularizers.l2(0.)))\n",
    "model_5.compile(loss = LOSS, optimizer = opt, metrics = METRICS)\n",
    "print(\"FineTuneing!!\")\n",
    "\n",
    "cv_models = [model_1, model_2, model_3, model_4, model_5]\n",
    "cv_models[4].summary()\n",
    "\n",
    "print(\"model取得完了\")\n",
    "print(\"モデルの取得時間：\", str(time.time() - T_model_in), \"[sec]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_models[4].layers[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(use_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKFold用のデータジェネレータ\n",
    "#CV_NUM = 0\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    height_shift_range = 0.15,\n",
    "    width_shift_range = 0.15\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = training_df,\n",
    "    #dataframe = train_data_gen(training_item_count, data_seed),\n",
    "    x_col='image_id',\n",
    "    y_col='label',\n",
    "    directory='/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/train_images/',\n",
    "    target_size=target_size,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    seed = 94)\n",
    "\n",
    "\n",
    "# Validation_datagenでもAugumentationをすれば、TTA的に若干の精度向上が見込まれる\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = validation_df,\n",
    "    #dataframe = val_data_gen(training_item_count, data_seed),\n",
    "    x_col='image_id',\n",
    "    y_col='label',\n",
    "    directory='/Users/kushi/TechLife/kaggle_road/06_cassava/dataset/train_images/',\n",
    "    target_size=target_size,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    seed = 94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習前準備\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NUM = 0\n",
    "# コールバック全般設定(出来れば学習中に変化させたい)\n",
    "# 学習率のスケジューラ(適当に作っているので、、、\n",
    "def lr_schedul(epoch):\n",
    "    x = 0.01\n",
    "    if epoch >= 1:\n",
    "        x = 0.005\n",
    "    elif epoch >= 3:\n",
    "        x = 0.0001\n",
    "    elif epoch >= 6:\n",
    "        x = 0.0005\n",
    "    \n",
    "    print(\"学習率は：『 \", str(x), \" 』\")\n",
    "    #print(\"  GPU使用状況の表示  \")\n",
    "    #pprint.pprint(get_gpu_info())\n",
    "    return x\n",
    "lr_decay = LearningRateScheduler(lr_schedul, verbose=1)\n",
    "\n",
    "# 学習率の上昇\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "                        monitor='val_loss',\n",
    "                        factor=0.2,\n",
    "                        patience=2,\n",
    "                        min_lr=0.00001\n",
    "                )\n",
    "\n",
    "# 早期停止条件\n",
    "es = EarlyStopping(monitor=\"accuracy\", min_delta=0.001, patience=2, verbose=1, mode='auto')\n",
    "\n",
    "# チェックポイントで定期的にモデルを保存する\n",
    "# ファイル名に(`str.format`を使って)エポック数を埋め込む\n",
    "#checkpoint_path = \"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/cp-{epoch:04d}.ckpt\"\n",
    "#checkpoint_path = \"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/model_\" + str(CV_NUM) + \"_cp-{epoch:04d}.h5\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = ModelCheckpoint(filepath = \"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/model_\" + str(CV_NUM) + \"_cp-{epoch:04d}.h5\", \n",
    "                                monitor='val_accuracy', \n",
    "                                verbose=0, \n",
    "                                save_best_only=True, \n",
    "                                save_weights_only=False, \n",
    "                                mode='min', \n",
    "                                period=1)\n",
    "hist = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用画像の準備\n",
    "tes00 = get_img(test_imgs[0])\n",
    "tes_im = tes00[np.newaxis,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# KFold的にfit_generatorを使う\n",
    "n_splits = 5\n",
    "T0 = time.time()\n",
    "\n",
    "for CV_NUM in range(n_splits):\n",
    "    T = time.time()\n",
    "    print(\"\")\n",
    "    print(\"cv_num：\", str(CV_NUM))\n",
    "    training_df = train_data_gen(training_item_count, data_seed)\n",
    "    validation_df = val_data_gen(training_item_count, data_seed)\n",
    "    \n",
    "    history = cv_models[CV_NUM].fit_generator(generator=train_generator,\n",
    "                                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                              validation_data=validation_generator,\n",
    "                                              validation_steps=STEP_SIZE_VALID,\n",
    "                                              epochs=EPOCHS,\n",
    "                                              verbose=1,\n",
    "                                              callbacks=[reduce_lr, es, cp_callback, hist],\n",
    "                                              shuffle=True,\n",
    "                                              workers=10\n",
    "                                             )\n",
    "    \n",
    "    # 評価工程\n",
    "    pred = cv_models[CV_NUM].predict(tes_im)\n",
    "    result = np.argmax(pred)\n",
    "    print(\"●〇●〇●モデル No：\", str(CV_NUM))\n",
    "    print(result)\n",
    "    print(pred)\n",
    "    \n",
    "    # 学習過程のhistoryを保存\n",
    "    hist_df = pd.DataFrame(hist.history)\n",
    "    hist_df.to_csv(\"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/history_model_\" + str(CV_NUM) + \".csv\")\n",
    "    # 学習後のモデルを丸ごと保存！\n",
    "    cv_models[CV_NUM].save(\"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/model_\" + str(CV_NUM) + \".h5\", include_optimizer=False)\n",
    "    print(\"SKFoldの処理時間：\", str(time.time() - T), \" [sec]\")\n",
    "\n",
    "print(\"学習の処理時間：\", str(time.time() - T0), \" [sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用画像について\n",
    "test_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes00 = get_img(test_imgs[0])\n",
    "plt.imshow(tes00)\n",
    "print(tes00.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes01 = tes00[np.newaxis,:,:,:]\n",
    "print(tes01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(tes01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(pred)\n",
    "print(result)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習後のモデルを丸ごと保存！\n",
    "model.save(\"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/model.h5\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histは、callbackで設定してる変数\n",
    "#hist_df = pd.DataFrame(history.history)\n",
    "hist_df = pd.DataFrame(hist.history)\n",
    "hist_df.to_csv(\"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acc画像の保存\n",
    "plt.figure()\n",
    "hist_df[['accuracy', 'val_accuracy']].plot()\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(os.path.join(\"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/\", \"acc.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss画像の保存\n",
    "plt.figure()\n",
    "hist_df[['loss', 'val_loss']].plot()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(os.path.join(\"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/\", \"loss.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labelのデータフレームを表示、なぜか先頭の1枚目が無かったので削除する\n",
    "print(train_label.shape)\n",
    "\n",
    "train_label2 = train_label[1:]\n",
    "train_label2.shape\n",
    "train_label2 =train_label2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 混合行列\n",
    "# 全データやると、だいたい560secかかるよ！\n",
    "T = time.time()\n",
    "pred_list = []\n",
    "i=0\n",
    "for i in range(len(imgs)//1):\n",
    "    im = get_img(imgs[i])\n",
    "    #print(imgs[i])\n",
    "    im = im[np.newaxis, :, :, :]\n",
    "    pred = model.predict(im)\n",
    "    pred = np.argmax(pred)\n",
    "    #print(pred)\n",
    "    \n",
    "    if i == 0:\n",
    "        pred_list = pred\n",
    "    elif i != 0:\n",
    "        pred_list = np.append(pred_list, pred)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"かうんと\", str(i))\n",
    "    #print(pred_list)\n",
    "print(\"処理時間：\", str(time.time() - T), \" [sec]\")    \n",
    "#print(confusion_matrix(y_true_multi, y_pred_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_df = pd.DataFrame(pred_list)\n",
    "#train_label2 = pd.DataFrame(train_label2)\n",
    "pred_list_df.columns = [\"pred\"]\n",
    "pred_list_df.astype(int)\n",
    "print(pred_list_df.shape)\n",
    "print(train_label2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_df[\"pred\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label2[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pred_list_df))\n",
    "print(type(train_label2))\n",
    "print(\"pred_list_df\", \n",
    "      pred_list_df.dtypes)\n",
    "\n",
    "print(\"train_label2\",\n",
    "      train_label2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([train_label2, pred_list_df], axis=1)\n",
    "print(result_df.dtypes)\n",
    "print(result_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"/Users/kushi/TechLife/kaggle_road/06_cassava/my_models/Add_Result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合行列\n",
    "cm = confusion_matrix(result_df[\"label\"], result_df[\"pred\"])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(result_df[\"label\"], result_df[\"pred\"]))\n",
    "print(precision_score(result_df[\"label\"], result_df[\"pred\"], average=\"macro\"))\n",
    "print(recall_score(result_df[\"label\"], result_df[\"pred\"], average='macro'))\n",
    "print(f1_score(result_df[\"label\"], result_df[\"pred\"], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(result_df[\"label\"], result_df[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用\n",
    "#history = model.fit(train_generator,\n",
    "##                  epochs = EPOCHS, \n",
    "#                 validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decay_steps = int(round(len(training_df)/batch_size))*epochs\n",
    "#cosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.2)\n",
    "\n",
    "#callbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "#model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(cosine_decay), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(np.argmax(pred[i]), \"：確率は　\", np.max(pred[i]), \"=======正解⇒\", np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(pred, axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習中の損失係数とAccuracyを可視化\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
